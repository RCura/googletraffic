library(osrm)
library(parallel)
library(dplyr)
library(rdrop2)
library(readxl)
library(stringr)
library(haven)
library(readxl)
library(pbmcapply)
library(tidyr)
library(stringr)
library(ggrepel)
library(ggthemes)
library(googleway)
library(googledrive)
library(writexl)
library(dplyr)
library(lubridate)
library(parallel)
library(pbmcapply)
library(tidyr)
library(stringr)
library(googledrive)
library(devtools)
library(pdftools)
library(jpeg)
library(xlsx)
library(dismo)
library(stargazer)
library(MASS)
library(deldir)
library(LearnGeom)
library(lfe)
library(dplyr)
library(stringr)
library(ngram)
library(stringdist)
library(exactextractr)
library(glmnet)
library(quanteda.textmodels) # devtools::install_github("quanteda/quanteda.svm")
library(geosphere)
library(googlesheets)
library(ggplot2)
library(lubridate)
library(tidyverse)
library(googlesheets4)
library(arrow)
#library(Rcpp)
#library(tesseract)
library(dtplyr)
library(dplyr)
library(bdscale)
library(googleway)
library(htmlwidgets)
library(webshot)
library(raster)
library(png)
library(plotwidgets)
library(httr)
#library(googletraffic)
#devtools::install_github("skgrange/gissr")
source("https://raw.githubusercontent.com/ramarty/Unique-Location-Extractor/master/R/load_ulex.R")
source(file.path(github_file_path, "Functions and Packages", "Tweet Classification", "tweet_classification.R"))
source(file.path(github_file_path, "Functions and Packages", "Clustering", "cluster_crashes_into_clusters.R"))
source(file.path(github_file_path, "Functions and Packages", "Clustering", "cluster_crashes_into_unique_crashes.R"))
source(file.path(github_file_path, "Functions and Packages", "commonly_used_functions.R"))
source("https://raw.githubusercontent.com/ramarty/fast-functions/master/R/functions_in_chunks.R")
source("https://raw.githubusercontent.com/ramarty/Waze/master/append_waze_from_s3.r")
# For downloading Waze Data
#source("https://raw.githubusercontent.com/worldbank/Data-Collaboratives/waze/r/Code/append_waze_from_s3.r?token=ACYONTQSWBR4FCSYELW2CVS7CGR7Y")
#source("https://raw.githubusercontent.com/worldbank/Data-Collaboratives/waze/r/Code/append_waze_from_s3.r?token=ACYONTVICRXERUR7GIK6F2C6QZYUY")
library(googletraffic)
# Download Google Traffic Data from AWS
# Setup ------------------------------------------------------------------------
# Set AWS Keys
Sys.setenv("AWS_ACCESS_KEY_ID" = api_keys_df$Key[(api_keys_df$Account %in% "robmarty3@gmail.com") & (api_keys_df$Service %in% "AWS_ACCESS_KEY_ID")],
"AWS_SECRET_ACCESS_KEY" = api_keys_df$Key[(api_keys_df$Account %in% "robmarty3@gmail.com") & (api_keys_df$Service %in% "AWS_SECRET_ACCESS_KEY")],
"AWS_DEFAULT_REGION" = "us-east-2")
# Download Data ----------------------------------------------------------------
#### Load grid
grid_df <- readRDS(file.path(google_traffic_dir, "RawData", "nairobi_grid.Rds"))
#### Grab file names
s3_files <- get_bucket(bucket="wb-dime-googletraffic", max=Inf, url_style="path", prefix="nairobi_png/")
get_s3_keys <- function(i, s3_files) s3_files[i]$Contents$Key
s3_keys <- lapply(1:length(s3_files), get_s3_keys, s3_files) %>% unlist
s3_keys <- s3_keys[!endsWith(s3_keys, "/")]
s3_keys <- paste0("wb-dime-googletraffic/", s3_keys)
#### Grab time stamps
time_stamps <- s3_keys %>%
str_replace_all(".*_utc", "") %>%
str_replace_all("_id.*", "") %>%
unique()
for(time_stamp_i in time_stamps){
s3_keys_time_i <- s3_keys %>% str_subset(time_stamp_i)
out_path_tiff <- file.path(google_traffic_dir, "FinalData", "individual_rasters", paste0("gt_nairobi_utc",time_stamp_i,".tiff"))
if(!file.exists(out_path_tiff)){
r_list <- lapply(s3_keys_time_i, function(s3_key_i){
print(paste0("Processing: ", s3_key_i))
id_i <- s3_key_i %>%
str_replace_all(".*_", "") %>%
str_replace_all(".png|id", "") %>%
as.numeric()
param_i <- grid_df[grid_df$id %in% id_i,]
r_i <- aws.s3::s3read_using(gt_load_png_as_traffic_raster,
object = paste0("s3://",s3_key_i),
location = c(param_i$latitude, param_i$longitude),
#
# latitude = param_i$latitude,
# longitude = param_i$longitude,
height = param_i$height,
width = param_i$width,
zoom = param_i$zoom)
return(r_i)
})
## Mosaic individual rasters together
names(r_list)    <- NULL
#r_list$fun       <- max
r_list$tolerance <- 999
r_all <- do.call(raster::merge, r_list)
## Export
#saveRDS(r_all, file.path(google_traffic_dir, "FinalData", "individual_rasters", paste0("gt_nairobi_utc",time_stamp_i,".Rds")))
writeRaster(r_all, out_path_tiff, overwrite = T)
rm(r_all)
#gc()
}
}
# r <- r_list[[8]]
# r[][is.na(r[])] <- 0
# pal <- colorNumeric(c("#0C2C84", "#41B6C4", "#FFFFCC"), values(r),
#                     na.color = "transparent")
#
# leaflet() %>% addTiles() %>%
#   addRasterImage(r, colors = pal, opacity = 0.8) %>%
#   addLegend(pal = pal, values = values(r),
#             title = "Surface temp")
# Make Grid Data
# Make Grid --------------------------------------------------------------------
#### Nairobi
nbo_sp <- readRDS(file.path(gadm_dir, "RawData", "gadm36_KEN_3_sp.rds"))
nbo_sp <- nbo_sp[nbo_sp$NAME_1 %in% "Nairobi",]
#### Roads
roads_sp <- readRDS(file.path(osm_dir, "FinalData", "rds_files_20210608", "gis_osm_roads_free_1_nairobi.Rds"))
roads_sp$name <- roads_sp$name %>% tolower()
roads_sub_sp <- roads_sp[roads_sp$name %in% c("mombasa road",
"thika road",
"waiyaki way",
"jogoo road"),]
roads_sub_sp <- roads_sub_sp %>% gBuffer(byid = T, width = 15/1000/111.12)
roads_sub_sp <- raster::intersect(roads_sub_sp, nbo_sp)
roads_sub_sp <- raster::aggregate(roads_sub_sp, by = "name")
# Function to extract data -----------------------------------------------------
extract_gt_data <- function(files_date, locations_sp){
locations_df <- map_df(files_date, function(file_i){
r <- raster(file_i)
#r[][r[] %in% 0] <- NA
count_1 <- function(x){
sum(x==1, na.rm = T)
}
count_2 <- function(x){
sum(x==2, na.rm = T)
}
count_3 <- function(x){
sum(x==3, na.rm = T)
}
count_4 <- function(x){
sum(x==4, na.rm = T)
}
locations_sp$count_1 <- exact_extract(x = r,
y = locations_sp,
fun = count_1,
summarize_df = T,
max_cells_in_memory = 3e07)
locations_sp$count_2 <- exact_extract(x = r,
y = locations_sp,
fun = count_2,
summarize_df = T,
max_cells_in_memory = 3e07)
locations_sp$count_3 <- exact_extract(x = r,
y = locations_sp,
fun = count_3,
summarize_df = T,
max_cells_in_memory = 3e07)
locations_sp$count_4 <- exact_extract(x = r,
y = locations_sp,
fun = count_4,
summarize_df = T,
max_cells_in_memory = 3e07)
locations_sp$unix_time <- file_i %>%
str_replace_all(".*utc", "") %>%
str_replace_all(".tiff", "")
return(locations_sp@data)
})
return(locations_df)
}
# Create list of raster files --------------------------------------------------
files <- file.path(google_traffic_dir, "FinalData", "individual_rasters") %>%
list.files(full.names = T)
files_df <- files %>%
as.data.frame() %>%
dplyr::rename(filepath = ".") %>%
mutate(unix_time = filepath  %>%
str_replace_all(".*utc", "") %>%
str_replace_all(".tiff", "")) %>%
mutate(datetime_eat = unix_time %>%
as.numeric %>%
as.POSIXct(origin = "1970-01-01 00:00:00", tz = "UTC") %>%
round_date(unit = "hour") %>%
with_tz(tzone = "Africa/Nairobi")) %>%
mutate(date = datetime_eat %>% as.Date()) %>%
group_by(date) %>%
dplyr::mutate(n_obs_date = n()) %>%
ungroup()
files_df <- files_df %>%
dplyr::filter(n_obs_date == 24)
# Extract traffic data: Nairobi ADM --------------------------------------------
for(date_i in unique(files_df$date)){
print(date_i)
OUT_PATH <- file.path(papernotes_dir, "Google Traffic Blog", "Data", "google_traffic", paste0("grid_data_", date_i, ".Rds"))
if(!file.exists(OUT_PATH)){
files_date <- files_df %>%
dplyr::filter(date %in% date_i) %>%
pull(filepath)
# HEREHERE
grid_data_df <- extract_gt_data(files_date, nbo_sp)
saveRDS(grid_data_df, OUT_PATH)
rm(grid_data_df)
}
}
# Extract traffic data: Nairobi roads ------------------------------------------
for(date_i in rev(unique(files_df$date))){
print(date_i)
OUT_PATH <- file.path(papernotes_dir, "Google Traffic Blog", "Data", "google_traffic", paste0("roads_data_", date_i, ".Rds"))
if(!file.exists(OUT_PATH)){
files_date <- files_df %>%
dplyr::filter(date %in% date_i) %>%
pull(filepath)
# HEREHERE
grid_data_df <- extract_gt_data(files_date, roads_sub_sp)
saveRDS(grid_data_df, OUT_PATH)
rm(grid_data_df)
}
}
# Append Grid Data
# Load data --------------------------------------------------------------------
traffic_adm_df <- file.path(papernotes_dir, "Google Traffic Blog", "Data", "google_traffic") %>%
list.files(full.names = T,
pattern = "grid_data_") %>%
map_df(readRDS)
traffic_roads_df <- file.path(papernotes_dir, "Google Traffic Blog", "Data", "google_traffic") %>%
list.files(full.names = T,
pattern = "roads_data_") %>%
map_df(readRDS)
# Clean data -------------------------------------------------------------------
traffic_adm_df <- traffic_adm_df %>%
mutate(datetime_eat = unix_time  %>%
as.numeric() %>%
as.POSIXct(origin = "1970-01-01 00:00:00", tz = "UTC") %>%
round_date(unit = "hour") %>%
with_tz(tzone = "Africa/Nairobi"))
traffic_roads_df <- traffic_roads_df %>%
mutate(datetime_eat = unix_time  %>%
as.numeric() %>%
as.POSIXct(origin = "1970-01-01 00:00:00", tz = "UTC") %>%
round_date(unit = "hour") %>%
with_tz(tzone = "Africa/Nairobi"))
# ADM3 =========================================================================
# Create variables -------------------------------------------------------------
traffic_adm_sum_df <- traffic_adm_df %>%
mutate(count_all = count_1 + count_2 + count_3 + count_4) %>%
group_by(NAME_3) %>%
mutate(count_all_max = max(count_all)) %>%
ungroup() %>%
mutate(prop_1 = count_1/count_all_max,
prop_2 = count_2/count_all_max,
prop_3 = count_3/count_all_max,
prop_4 = count_4/count_all_max) %>%
mutate(count_34 = count_3 + count_4,
count_234 = count_2 + count_3 + count_4,
count_1234 = count_1 + count_2 + count_3 + count_4)
# Export data ------------------------------------------------------------------
saveRDS(traffic_adm_sum_df,
file.path(papernotes_dir, "Google Traffic Blog", "Data", "google_traffic", "adm3_data.Rds"))
# Nairobi ======================================================================
# Create variables -------------------------------------------------------------
traffic_adm_sum_df <- traffic_adm_df %>%
group_by(datetime_eat) %>%
dplyr::summarise_at(vars(count_1, count_2, count_3, count_4), sum) %>%
ungroup() %>%
mutate(count_all = count_1 + count_2 + count_3 + count_4) %>%
mutate(count_all_max = max(count_all)) %>%
mutate(prop_1 = count_1/count_all_max,
prop_2 = count_2/count_all_max,
prop_3 = count_3/count_all_max,
prop_4 = count_4/count_all_max) %>%
mutate(count_34 = count_3 + count_4,
count_234 = count_2 + count_3 + count_4,
count_1234 = count_1 + count_2 + count_3 + count_4)
# Export data ------------------------------------------------------------------
saveRDS(traffic_adm_sum_df,
file.path(papernotes_dir, "Google Traffic Blog", "Data", "google_traffic", "nbo_data.Rds"))
# Roads ========================================================================
# Create variables -------------------------------------------------------------
traffic_roads_sum_df <- traffic_roads_df %>%
mutate(count_all = count_1 + count_2 + count_3 + count_4) %>%
group_by(name) %>%
mutate(count_all_max = max(count_all)) %>%
ungroup() %>%
mutate(prop_1 = count_1/count_all_max,
prop_2 = count_2/count_all_max,
prop_3 = count_3/count_all_max,
prop_4 = count_4/count_all_max) %>%
mutate(count_34 = count_3 + count_4,
count_234 = count_2 + count_3 + count_4,
count_1234 = count_1 + count_2 + count_3 + count_4)
# Export data ------------------------------------------------------------------
saveRDS(traffic_roads_sum_df,
file.path(papernotes_dir, "Google Traffic Blog", "Data", "google_traffic", "roads_data.Rds"))
# Analysis
# Load data ------------------------------------------------------------------
adm3_df  <- readRDS(file.path(papernotes_dir, "Google Traffic Blog", "Data", "google_traffic", "adm3_data.Rds"))
nbo_df   <- readRDS(file.path(papernotes_dir, "Google Traffic Blog", "Data", "google_traffic", "nbo_data.Rds"))
roads_df <- readRDS(file.path(papernotes_dir, "Google Traffic Blog", "Data", "google_traffic", "roads_data.Rds"))
# Clean data -------------------------------------------------------------------
adm3_df <- adm3_df %>%
dplyr::mutate(hour = datetime_eat %>% hour())
nbo_df <- nbo_df %>%
dplyr::mutate(hour = datetime_eat %>% hour())
roads_df <- roads_df %>%
dplyr::mutate(hour = datetime_eat %>% hour())
# Trends Over Time -------------------------------------------------------------
p <- nbo_df %>%
dplyr::select(datetime_eat, count_2, count_3, count_4) %>%
pivot_longer(-datetime_eat) %>%
dplyr::mutate(name = case_when(
name == "count_2" ~ "Medium Traffic",
name == "count_3" ~ "High Traffic",
name == "count_4" ~ "Heavy Traffic"
)) %>%
dplyr::mutate(name = name %>%
factor(levels = rev(c("Medium Traffic",
"High Traffic",
"Heavy Traffic")))) %>%
ggplot(aes(x = datetime_eat,
y = value,
fill = name)) +
## Election
geom_vline(xintercept = ymd_hms("2022-08-09 00:00:00",
tz = "Africa/Nairobi"),
color = "black") +
geom_text(aes(x = ymd_hms("2022-08-10 19:00:00",
tz = "Africa/Nairobi"),
y = 700000,
label = "Election")) +
## Winner Announced
geom_vline(xintercept = ymd_hms("2022-08-15 00:00:00",
tz = "Africa/Nairobi"),
color = "black") +
geom_text(aes(x = ymd_hms("2022-08-15 03:00:00",
tz = "Africa/Nairobi"),
y = 700000,
label = "Winner\nAnnounced"),
hjust = 0) +
## Supreme Court
geom_vline(xintercept = ymd_hms("2022-09-05 00:00:00",
tz = "Africa/Nairobi"),
color = "black") +
geom_text(aes(x = ymd_hms("2022-09-05 03:00:00",
tz = "Africa/Nairobi"),
y = 700000,
label = "Supreme Court\nAffirms Result"),
hjust = 0) +
geom_col(width = 4000) +
scale_fill_manual(values = rev(c("#F7833D",
"#EC2427",
"#6D1318"))) +
labs(x = NULL,
y = "Number of Pixels",
#title = "Trends in Hourly Traffic",
fill = "Traffic") +
theme_classic2() +
theme(plot.title = element_text(face = "bold")) +
xlim(c(
ymd_hms("2022-07-29 03:00:00",
tz = "Africa/Nairobi"),
ymd_hms("2022-09-10 00:00:00",
tz = "Africa/Nairobi")
))
ggsave(p,
filename = file.path(papernotes_dir, "Google Traffic Blog", "Figures",
"nbo_traffic_trends.png"),
height = 3.2,
width = 10)
# Change Map -------------------------------------------------------------------
#### Prep data
adm3_sp <- readRDS(file.path(gadm_dir, "RawData", "gadm36_KEN_3_sp.Rds"))
adm3_sp <- adm3_sp[adm3_sp$NAME_1 %in% "Nairobi",]
adm3_sum_df <- adm3_df %>%
dplyr::mutate(date = datetime_eat %>% as.Date) %>%
dplyr::mutate(period = case_when(
date %in% ymd("2022-08-03") ~ "before",
date %in% ymd("2022-08-10") ~ "after"
)) %>%
dplyr::filter(!is.na(period)) %>%
group_by(NAME_3, period) %>%
dplyr::summarise(count_34 = sum(count_34),
count_1234 = sum(count_1234)) %>%
ungroup() %>%
group_by(NAME_3) %>%
dplyr::mutate(count_1234_before = count_1234[period %in% "before"]) %>%
ungroup() %>%
pivot_wider(id_cols = c(NAME_3, count_1234_before),
names_from = period,
values_from = count_34) %>%
dplyr::mutate(change = after - before,
change_rel_base = change / count_1234_before,
per_change = (after - before) / before)
adm3_sp <- merge(adm3_sp, adm3_sum_df, by = "NAME_3")
adm3_sf <- adm3_sp %>% st_as_sf()
adm3_sf$change %>% max()
#### Make figure
p <- ggplot() +
geom_sf(data = adm3_sf,
aes(fill = change_rel_base)) +
scale_fill_distiller(palette = "Spectral",
direction = 1,
breaks = c(-0.0035,
-0.026),
labels = c("Least\nReduction",
"Most\nReduction")) +
labs(fill = "Reduction\nin Traffic",
#title = "Reduction in Traffic from Before and After Election",
caption = "To compute change in traffic, we use the day after the election (August 10) and the date from a week prior (August 3). We rely on traffic categorized as 'red'
or 'dark red' according to Google. Change in traffic is computed relative to the size of the road network; specifically, change = (change in red or dark red
pixels)/(total green, orange, red, or dark red pixels at baseline).") +
theme_void() +
theme(plot.title = element_text(face = "bold"),
plot.caption = element_text(size = 6, hjust = 0))
ggsave(p,
filename = file.path(papernotes_dir, "Google Traffic Blog", "Figures",
"nbo_traffic_change.png"),
height = 4.75,
width = 7)
library(googletraffic)
help("gt_load_png_as_traffic_raster")
help(gt_make_grid)
help("gt_make_html")
help(gt_make_png)
help("gt_make_raster_from_grid")
help("gt_make_raster_from_polygon")
help(gt_make_rsater)
help("gt_make_raster")
help(gt_mosaic)
library(tidyverse)
library(readxl)
df <- read_xls("~/Desktop/full_route_list (2).xlsx")
library(tidyverse)
library(readxl)
df <- read_xls("~/Desktop/full_route_list (2).xlsx")
library(tidyverse)
library(readxl)
df <- read_xls("~/Desktop/full_route_list (2).xlsx")
df <- read_xls("~/Desktopa/full_route_list (2).xlsx")
df <- read_csv("~/Desktop/full_route_list.csv")
head(df)
library(tidyverse)
library(readxl)
df <- read_csv("~/Desktop/full_route_list.csv")
rows <- sample(nrow(df))
df <- df[rows,]
head(df)
remove.packages("googletraffic")
roxygen2::roxygenise("~/Documents/Github/googletraffic")
roxygen2::roxygenise("~/Documents/Github/googletraffic")
devtools::install_github("dime-worldbank/googletraffic")
library(googletraffic)
help(gt_make_raster_from_grid)
setwd("~/Documents/Github/googletraffic")
usethis::use_pkgdown()
#usethis::use_pkgdown_github_pages()
pkgdown::deploy_to_branch()
pkgdown::build_site()
library(googletraffic)
api_keys_df <- readr::read_csv("~/Dropbox/World Bank/Webscraping/Files for Server/api_keys.csv")
google_key <- api_keys_df |>
dplyr::filter(Service == "Google Directions API",
Account == "AIzaSyC5Wu7vIXEf82L4rJaEfbtAmmVl8MgZDyw") |>
dplyr::pull(Key)
google_key
api_keys_df <- readr::read_csv("~/Dropbox/World Bank/Webscraping/Files for Server/api_keys.csv")
api_keys_df <- readr::read_csv("~/Dropbox/World Bank/Webscraping/Files for Server/api_keys.csv")
api_keys_df
View(api_keys_df)
library(googletraffic)
api_keys_df <- readr::read_csv("~/Dropbox/World Bank/Webscraping/Files for Server/api_keys.csv")
google_key <- api_keys_df |>
dplyr::filter(Service == "Google Directions API",
Account == "satelliteieconnect@gmail.com") |>
dplyr::pull(Key)
google_key
library(googletraffic)
api_keys_df <- readr::read_csv("~/Dropbox/World Bank/Webscraping/Files for Server/api_keys.csv")
google_key <- api_keys_df |>
dplyr::filter(Service == "Google Directions API",
Account == "satelliteieconnect@gmail.com") |>
dplyr::pull(Key)
#### From Point
r <- gt_make_raster(location   = c(40.712778, -74.006111),
height     = 1000,
width      = 1000,
zoom       = 16,
google_key = google_key)
plot(r)
